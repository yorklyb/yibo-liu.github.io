<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252" charset="utf-8">
        <title>Yibo Liu - Ph.D. candidate </title>
<style type="text/css"></style></head>
    <body><table border="0" width="980px" align="center"><tbody><tr><td>
    
        </td><td valign="top">
<!--            <img src="images/cmuscslogo.gif">
                <img src="images/rilogo.png"> -->
        <br>
        <table style="font-size: 11pt;" border="0" width="100%">
            <tbody><tr>
                <td width="50%">
                    <!-- <img width="300" src="./index_files/mypic.jpeg" border="0"> -->
                    <!-- <img width="300" src="./index_files/mypic2.jpg" border="0"> -->
                    <!-- <img width="250" src="./index_files/mypic3.jpg" border="0"> -->
                    <img width="250" src="./index_files/yibo.jpg" border="0">
                </td>
                <td>
                    <font face="helvetica , ariel, &#39;sans serif&#39;" size="6"> 
                        <b>Yibo Liu</b><br><br>
                    </font>
                    <font face="helvetica , ariel, &#39;sans serif&#39;" size="4"> 
                        Ph.D. Candidate<br>
                        York University, Toronto<br><br>
                        Associate Researcher (Part-Time)<br>
			Noah Ark's Lab, Markham<br><br>
                        buaayorklau at gmail.com<br><br>
                        [<a href="https://github.com/yorklyb" border="0">GitHub</a>]
                        [<a href="https://scholar.google.ca/citations?user=zqDgDQ4AAAAJ&hl=en&oi=ao" border="0">Google Scholar</a>]<br>
                        [<a href="index_files/yibo_liu_cv.pdf" border="0">Resume/CV</a>]
                        [<a href="https://www.linkedin.com/in/yibo-liu/" border="0">Linkedin</a>]
                    </font>
                </td>
            </tr>
        </tbody></table> 
        <p>
        </p><hr size="2" align="left" noshade="">
        <p>
        
        <font face="helvetica, ariel, &#39;sans serif&#39;">
        <!--</font></p><h2><font face="helvetica, ariel, &#39;sans serif&#39;">About Me</font></h2><font face="helvetica, ariel, &#39;sans serif&#39;">-->
	I am Yibo Liu, currently a fifth-year Ph.D. student at York University, supervised by Professor <a href="https://lassonde.yorku.ca/users/jjshan">Jinjun Shan</a>. I obtained my bachelor's degree and master's degree in 2017 and 2020. respectively, both at <a href="https://ev.buaa.edu.cn/">Beihang University (Beijing University of Aeronautics and Astronautics)</a>. <br><br>
	My Ph.D. career started with research in robotic vision. Since June 2022, I have been working as an associate researcher (part-time internship) at Huawei Noah Ark's Lab in Markham, where I conduct product-oriented academic research. My research interest lies in the domain of 3D Computer Vision, AIGC, and Embodied AI. 
		<br><br>
		<a href="https://arxiv.org/pdf/2407.06516v1">VQA-Diff (ECCV2024)</a>, <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Liu_MV-DeepSDF_Implicit_Modeling_with_Multi-Sweep_Point_Clouds_for_3D_Vehicle_ICCV_2023_paper.html">MV-DeepSDF (ICCV2023)</a>, 
	and <a href="https://arxiv.org/abs/2309.16110">Learning Effective NeRFs and SDFs Representations with 3D Generative Adversarial Networks for 3D Object Generation</a>  (Top-3 winner of <a href="https://omniobject3d.github.io/challenge.html">OmniObject3D challenge</a> at ICCV2023) summarize my work. 
        <br>
        
        <!-- <br><br> -->
        </p><hr size="2" align="left" noshade="">

        <h3>News </h3>
        <font face="helvetica, ariel, &#39;sans serif&#39;">
            <span style="font-size: 10pt;">
<!--             <b>[Sept 2023]</b> I was included on a list of <a href="https://www.technologyreview.com/innovator/richard-zhang/">35 Innovators Under 35</a> by MIT Technology Review! Please see <a href="https://blog.adobe.com/en/publish/2023/09/12/adobe-research-scientist-named-top-innovator-under-35-mit-technology-review">this article</a> by Adobe and <a href="https://www.youtube.com/watch?v=YQW32sf9noE">this 5 min overview video</a> for more information.<br> -->
            <!-- <b>[Nov 2023]</b> I appeared on the <a href="https://twimlai.com/podcast/twimlai/visual-generative-ai-ecosystem-challenges/">TWiML podcast</a>, discussing building a healthy GenAI ecosystem for creators, consumers, and contributors. Links: <a href="https://open.spotify.com/episode/6V8zgyf9f6Q6p7rdRhrbpU?si=6670478bdffd46b5">Spotify</a>, <a href="https://podcasts.apple.com/us/podcast/visual-generative-ai-ecosystem-challenges-with-richard/id1116303051?i=1000635452895">Apple</a>, <a href="https://dcs.megaphone.fm/MLN6292733087.mp3">File</a> (40 min); <a href="https://www.youtube.com/watch?v=PdHmoqS70r0">YouTube</a> (51 min).<br> -->
            <b>[Sep 2024]</b> I will be giving a talk at the University of Toronto (Toronto Computational Imaging Group). </a>.<br>
            <b>[Sep 2024]</b> I'm invited to give a talk at <a href="https://space.bilibili.com/483478083?spm_id_from=333.337.0.0">3D Vision Workshop (3D 视觉工坊)</a>.<br>
		<b>[Aug 2024]</b> VQA-Diff was accepted to ECCV 2024.<br>
            <b>[Oct 2023]</b>  Got 3rd place in the OmniObject Challenge (AGIC) at ICCV 2023.<br>
            <b>[Sep 2023]</b> MV-DeepSDF was accepted to ICCV 2023.<br>
            <!-- <b>[May 2019]</b> Our work on anti-aliasing convolutional networks has been accepted to ICML 2019. Try anti-aliasing your convnet <a href="https://github.com/adobe/antialiased-cnns">here</a>!<br> -->
            <!-- <b>[Aug 2018]</b> I will be presenting at the Thesis Fast Forward session at SIGGRAPH on Tuesday 8/14, 2:00pm.<br> -->
            <!-- <b>[Jun 2018]</b> We will be presenting our <a href="https://richzhang.github.io/PerceptualSimilarity/">project</a> on perceptual metrics at CVPR, Tuesday 6/19, 10:10am. Try our metric <a href="https://github.com/richzhang/PerceptualSimilarity">here</a>!<br> -->
            <!-- <b>[May 2018]</b> I have <a href="./index_files/graduation.jpg">graduated</a> from UC Berkeley and have joined Adobe Research as a Research Scientist in San Francisco! -->
            </span>

<!--         </p><hr size="2" align="left" noshade="">

        <h3>Internship </h3>
        <font face="helvetica, ariel, &#39;sans serif&#39;">
            <span style="font-size: 10pt;">
            If you have similar interests and are interested in collaborating during a Summer 2023 internship, I'd be happy to hear from you! <b>Please apply <a href="https://research.adobe.com/careers/internships/">here</a> first</b>. Tell me about your past research experience and what you would potentially like to do. The goal of an internship is a publication, usually CVPR or SIGGRAPH. Interns are typically PhD students; the number of slots is limited, so we unfortunately cannot accept everyone.
            </span>
        </font>
 -->
        </p><hr size="2" align="left" noshade="">

        <h2>Selected Publications </h2>
        <font face="helvetica, ariel, &#39;sans serif&#39;">
            <table cellspacing="15">
				<tbody>
                <tr>
                    <td width="30%" align=center>
                        <img width="250" align="center" src="./index_files/vqadiff.png" border="0"> &nbsp;

			    
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>VQA-Diff: Exploiting VQA and Diffusion for Zero-Shot Image-to-3D Vehicle Asset Generation in Autonomous Driving</b> <br> <br>
                        <span style="font-size: 10pt;">
			<b>Yibo Liu *</b>,
                        Zheyuan Yang *, 
                        Guile Wu, 
			Yuan Ren, Kejian Lin, Bingbing Liu, Yang Liu, Jinjun Shan
                        <br> <br>
                        To appear in ECCV, 2024. <br> <br>
                        [<a href="https://arxiv.org/pdf/2407.06516v1">Paper</a>]
                        <br>
                    </td>
                </tr>
                <tr>
                    <td width="30%" align=center>
                        <img width="250" align="center" src="./index_files/mvdeepsdf.png" border="0"> &nbsp;
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>MV-DeepSDF: Implicit Modeling with Multi-Sweep Point Clouds for 3D Vehicle Reconstruction in Autonomous Driving</b> <br> <br>
                        <span style="font-size: 10pt;">
                        <b>Yibo Liu </b>,
                        Kelly Zhu, 
                        Guile Wu, 
			Yuan Ren, Bingbing Liu, Yang Liu, Jinjun Shan
                        <br> <br>
                        ICCV, 2023. <br><br>
                        [<a href="https://openaccess.thecvf.com/content/ICCV2023/html/Liu_MV-DeepSDF_Implicit_Modeling_with_Multi-Sweep_Point_Clouds_for_3D_Vehicle_ICCV_2023_paper.html">Paper</a>]
                        [<a href="https://www.youtube.com/watch?v=HONluMoFkeI">Video (YouTube)</a>]
			[<a href="https://www.bilibili.com/video/BV1zK4y1w7mQ/">Video (Bilibili)</a>]
			[<a href="index_files/iccvposter.pdf">Poster</a>]
                        <br>
                    </td>
                </tr>
                <tr>
                    <td width="30%" align=center>
                        <img width="250" align="center" src="https://lazydiffusion.github.io/static/images/teaser.png" border="0"> &nbsp;
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>Lazy Diffusion Transformer for Interactive Image Editing</b><br>
                        <span style="font-size: 10pt;">
                        <a href="https://yotamnitzan.github.io/">Yotam Nitzan</a>, 
                        <a href="https://www.cs.huji.ac.il/w~wuzongze/">Zongze Wu</a>, 
                        Richard Zhang,
                        <a href="https://research.adobe.com/person/eli-shechtman/">Eli Shechtman</a>, 
                        <a href="https://danielcohenor.com/">Daniel Cohen-Or</a>, 
                        <a href="https://taesung.me/">Taesung Park</a>, 
                        <a href="http://mgharbi.com/">Michael Gharbi</a>
                        <br>
                        ECCV, 2024. <br>
                        [<a href="https://arxiv.org/abs/2404.12382">Paper</a>]
                        [<a href="https://lazydiffusion.github.io/">Webpage</a>]
                        <br>
                    </td>
                </tr>
                <tr>
                    <td width="30%" align=center>
                        <img width="150" align="center" src="index_files/teaser_dmd.gif" border="0"> &nbsp;
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>One-step Diffusion with Distribution Matching Distillation</b> <br>
                        <span style="font-size: 10pt;">
                        <a href="https://tianweiy.github.io/">Tianwei Yin</a>, 
                        <a href="http://mgharbi.com/">Michael Gharbi</a>, 
                        Richard Zhang,
                        <a href="https://research.adobe.com/person/eli-shechtman/">Eli Shechtman</a>,
                        <a href="https://people.csail.mit.edu/fredo/">Fredo Durand</a>,
                        <a href="https://billf.mit.edu/">William T. Freeman</a>,
                        <a href="https://taesung.me/">Taesung Park</a>
                        <br>
                        In CVPR, 2024. <br>
                        [<a href="https://arxiv.org/abs/2311.18828">Paper</a>]
                        [<a href="https://tianweiy.github.io/dmd/">Webpage</a>]
                        [<a href="https://www.youtube.com/watch?v=3vo6mzk9K4s&list=TLGGlJBiJ80Rt-wwMTEyMjAyMw">Teaser</a>]
                        [<a href="index_files/bibtex_dmd2023.txt">Bibtex</a>]
                        <br>
                    </td>
                </tr>
                <tr>
            </tbody></table>

       

        <h2>Organization, Committees </h2>
        <span style="font-size: 10pt;">
        <a href="https://she-workshop.github.io/">Sketching for Human Expressivity (SHE)</a> at ECCV 2022 (co-organizer)<br>
        <a href="https://data.vision.ee.ethz.ch/cvl/aim19/">Advances in Image Manipulation (AIM)<a> at ICCV 2019 (co-organizer)<br>
        CVPR 2020, 2021, 2023 (Area Chair)<br>
        BMVC 2022 (Area Chair)<br>

        <h2>Awards </h2>
        <span style="font-size: 10pt;">
        MIT Technology Review, <a href="https://www.technologyreview.com/innovator/richard-zhang/">35 Innovators Under 35</a>, 2023<br>
        Reviewer recognitions, CVPR 2019, NeurIPS 2019, ECCV 2020, NeurIPS 2020, ECCV 2022<br>
        Thesis Fast Forward, Best Presentation, SIGGRAPH 2018<br>
        <a href="https://research.adobe.com/fellowship/">Adobe Research Fellowship</a> 2017<br>

<!--         <h2>Tech Transfers </h2>
        <span style="font-size: 10pt;">
        Colorize Photo, Photoshop Elements 2020<br>
        Colorize, Photoshop Neural Filters 2020, 2021<br>
        Landscape Mixer, Photoshop Neural Filters 2021<br>
        Smart Portrait, Photoshop Neural Filters 2021<br>
        </span> -->

        <h2>Student collaborators/interns</h2>
        I have gotten to work with some wonderful collaborators.<br>

        <!-- <h3>Internship </h3> -->
<!--         <br>
        <font face="helvetica, ariel, &#39;sans serif&#39;">
            <span style="font-size: 10pt;">
            If you have similar interests and are interested in collaborating during a summer 2021 internship, please feel free to contact me! Tell me about your past research experience and what you would potentially like to do. The goal of an internship is a publication, usually CVPR or SIGGRAPH. For example, see my NIPS 2017 and CVPR 2018 papers, which were from my summer 2017 internship. Interns are almost all PhD students; the number of slots is limited, so we unfortunately cannot accept everyone.<br>
            </span>
        </font> -->

        <!-- <h3>@Adobe</h3> -->
        <br>
         <span style="font-size: 14pt;">
            <b>@Adobe</b>
        </span>

        <span style="font-size: 10pt;">
        <!-- <p> -->
        <dl class="dl-horizontal">
            <dt><b>PhD/MS [interns]</b></dt>
            <a href="https://tianweiy.github.io/">Tianwei Yin</a>, MIT<br>
            <a href="https://joaanna.github.io/">Joanna Materzynska</a>, MIT<br>
            <a href="https://twizwei.github.io/">Yiran Xu</a>, UMaryland<br>
            <a href="https://alii-ganjj.github.io/">Alireza Ganjdanesh</a>, UMaryland<br>
            <a href="https://jitengmu.github.io/">Jiteng Mu</a>, UC San Diego<br>
            <a href="http://peterwang512.github.io/">Sheng-Yu Wang</a>, CMU <br>
            Xiaojuan Wang, UWashington <br>
            <a href="https://yossigandelsman.github.io/">Yossi Gandelsman</a>, UC Berkeley <br>
            <a href="https://yinboc.github.io/">Yinbo Chen</a>, UC San Diego<br>
            <a href="https://nupurkmr9.github.io//">Nupur Kumari</a>, CMU<br>
            Minguk Kang, POSTTECH<br>
            <a href="https://dave.ml/">Dave Epstein</a>, UC Berkeley<br>
            <a href="https://gauravparmar.com/">Gaurav Parmar</a>, CMU<br>
            <a href="https://yotamnitzan.github.io/">Yotam Nitzan</a>, Tel Aviv University<br>
            <a href="https://homes.cs.washington.edu/~royorel/">Roy Or-El</a>, UW<br>
            <a href="http://people.csail.mit.edu/lrchai/">Lucy Chai</a>, MIT (Fellowship winner, 2021)<br>
            <a href="https://lychenyoko.github.io/">Yuchen Liu</a>, Princeton<br>
            <a href="https://people.cs.umass.edu/~dliu/">Difan Liu</a>, UMass Amherst<br>
            <a href="https://taesung.me/">Taesung Park</a>, UC Berkeley (Fellowship winner, 2020)<br>
            <a href="http://linji.me/">Ji Lin</a>, MIT<br>
            <a href="https://www.wpeebles.com/">William (Bill) Peebles</a>, UC Berkeley<br>
            <a href="https://www.alexandonian.com/">Alex Andonian</a>, MIT<br>
            <a href="https://utkarshojha.github.io/">Utkarsh Ojha</a>, UC Davis<br>
            <a href="http://arnabgho.github.io/">Arnab Ghosh</a>, Oxford<br>
            <a href="http://minyounghuh.com/">Minyoung (Jacob) Huh</a>, MIT<br>
            <a href="https://stamarot.webgr.technion.ac.il/">Tamar Rott Shaham</a>, Technion (Fellowship winner, 2020)<br>
            <a href="https://payeah.net">Peiye Zhuang</a>, UIUC<br>
            <a href="http://people.csail.mit.edu/smirnov/">Dima Smirnov</a>, MIT<br>
            <a href="https://www.cs.tau.ac.il/~noafish/">Noa Fish</a>, Tel Aviv<br>
            <br>

            <dt><b>Masters/Undergrad [interns]</b></dt>
            <a href="http://people.csail.mit.edu/stevenliu/">Steven Liu</a>, MIT<br>
            <a href="https://sjooyoo.github.io/">Seungjoo Yoo</a>, Korea Univ (WIT scholarship winner, 2019)<br>
            <br>

            <dt><b>PhD/MS [university collaborators]</b></dt>
            <a href="https://www.cs.princeton.edu/~pmanocha/">Pranay Manocha</a>, Princeton<br>
            <a href="https://rawanmg.github.io/">Rawan Alghofaili</a>, George Mason<br>
            <a href="http://alvinwan.com/">Alvin Wan</a>, UC Berkeley<br>
            <br>

            <!-- <dt><b>Undergrad [university collaborators]</b></dt> -->
            <!-- <a href="http://peterwang512.github.io/">Sheng-Yu Wang</a>, UC Berkeley <br> -->
        </dl>

        </span>

        <!-- <h3>@Berkeley</h3> -->
        <!-- <br> -->
         <span style="font-size: 14pt;">
            <b>@Berkeley</b>
        </span>

        <span style="font-size: 10pt;">
        <dl class="dl-horizontal">
          <dt><b>Undergraduates</b></dt>
            <a href="https://www.linkedin.com/in/xin-qin-4a83b9158/">Xin Qin</a>, next @ USC <br>
            <a href="https://www.linkedin.com/in/hemangjangle/">Hemang Jangle</a> <br>
            <a href="http://www.cs.utexas.edu/~alin/">Angela S. Lin</a>, next @ UT Austin <br>
            <a href="http://young-geng.xyz/">Xinyang Geng</a>, next @ UC Berkeley<br>
            <a href="https://tianheyu927.github.io/">Tianhe Yu</a>, next @ Stanford<br>
            <a href="https://www.linkedin.com/in/candrastefan/">Stefan A. Candra</a>
        </dl>

        <!-- </p> -->
        </span>
        <!-- </p><hr size="2" align="left" noshade=""> -->


        <h2>Teaching </h2>
        <!-- <a href="https://research.adobe.com/fellowship/">Adobe Research Fellowship</a> 2017 -->
        <span style="font-size: 12pt;">
        <b>Introduction to Artificial Intelligence (CS 188)</b>, UC Berkeley <br>
        <span style="font-size: 10pt;">
        Graduate Student Instructor (GSI) with Prof. <a href="http://people.eecs.berkeley.edu/~anca/">Anca Dragan</a> <br>
        Spring 2017<br>
        <br>
        <span style="font-size: 12pt;">
        <b>Computer Vision (CS 280)</b>, UC Berkeley <br>
        <span style="font-size: 10pt;">
        Graduate Student Instructor (GSI) with Prof. <a href="http://people.eecs.berkeley.edu/~efros/">Alexei A. Efros</a>, Prof. <a href="http://people.eecs.berkeley.edu/~trevor/">Trevor Darrell</a> <br>
        Spring 2016<br>
        <br>
        <span style="font-size: 12pt;">
        <b>Introduction to Circuits (ECE 2100)</b>, Cornell University <br>
        <span style="font-size: 10pt;">
        Teaching Assistant (TA) with Prof. <a href="https://molnargroup.ece.cornell.edu/">Alyosha Molnar</a> <br>
        Spring 2010<br>
        <br>

        <h2>My Name</h2>
        Confused by the contents of this page? Well, you may have been looking for Professor <a href="https://www.cs.sfu.ca/~haoz/" border="0">Richard Zhang</a> or Professor <a href="https://ryz.ece.illinois.edu/" border="0">Richard Zhang</a>. My Chinese name is 章睿嘉.

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-75897335-1', 'auto');
  ga('send', 'pageview');
</script>
            
</font></td></tr></tbody></table><iframe frameborder="0" scrolling="no" style="border: 0px; display: none; background-color: transparent;"></iframe><div id="GOOGLE_INPUT_CHEXT_FLAG" input="null" input_stat="{&quot;tlang&quot;:true,&quot;tsbc&quot;:true,&quot;pun&quot;:true,&quot;mk&quot;:false,&quot;ss&quot;:true}" style="display: none;"></div></body></html>
